{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 epoch,w is 2.600000,loss is 36.000000\n",
      "After 1 epoch,w is 1.160000,loss is 12.959999\n",
      "After 2 epoch,w is 0.296000,loss is 4.665599\n",
      "After 3 epoch,w is -0.222400,loss is 1.679616\n",
      "After 4 epoch,w is -0.533440,loss is 0.604662\n",
      "After 5 epoch,w is -0.720064,loss is 0.217678\n",
      "After 6 epoch,w is -0.832038,loss is 0.078364\n",
      "After 7 epoch,w is -0.899223,loss is 0.028211\n",
      "After 8 epoch,w is -0.939534,loss is 0.010156\n",
      "After 9 epoch,w is -0.963720,loss is 0.003656\n",
      "After 10 epoch,w is -0.978232,loss is 0.001316\n",
      "After 11 epoch,w is -0.986939,loss is 0.000474\n",
      "After 12 epoch,w is -0.992164,loss is 0.000171\n",
      "After 13 epoch,w is -0.995298,loss is 0.000061\n",
      "After 14 epoch,w is -0.997179,loss is 0.000022\n",
      "After 15 epoch,w is -0.998307,loss is 0.000008\n",
      "After 16 epoch,w is -0.998984,loss is 0.000003\n",
      "After 17 epoch,w is -0.999391,loss is 0.000001\n",
      "After 18 epoch,w is -0.999634,loss is 0.000000\n",
      "After 19 epoch,w is -0.999781,loss is 0.000000\n",
      "After 20 epoch,w is -0.999868,loss is 0.000000\n",
      "After 21 epoch,w is -0.999921,loss is 0.000000\n",
      "After 22 epoch,w is -0.999953,loss is 0.000000\n",
      "After 23 epoch,w is -0.999972,loss is 0.000000\n",
      "After 24 epoch,w is -0.999983,loss is 0.000000\n",
      "After 25 epoch,w is -0.999990,loss is 0.000000\n",
      "After 26 epoch,w is -0.999994,loss is 0.000000\n",
      "After 27 epoch,w is -0.999996,loss is 0.000000\n",
      "After 28 epoch,w is -0.999998,loss is 0.000000\n",
      "After 29 epoch,w is -0.999999,loss is 0.000000\n",
      "After 30 epoch,w is -0.999999,loss is 0.000000\n",
      "After 31 epoch,w is -1.000000,loss is 0.000000\n",
      "After 32 epoch,w is -1.000000,loss is 0.000000\n",
      "After 33 epoch,w is -1.000000,loss is 0.000000\n",
      "After 34 epoch,w is -1.000000,loss is 0.000000\n",
      "After 35 epoch,w is -1.000000,loss is 0.000000\n",
      "After 36 epoch,w is -1.000000,loss is 0.000000\n",
      "After 37 epoch,w is -1.000000,loss is 0.000000\n",
      "After 38 epoch,w is -1.000000,loss is 0.000000\n",
      "After 39 epoch,w is -1.000000,loss is 0.000000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "w = tf.Variable(tf.constant(5, dtype=tf.float32))  # set w=5 as initial\n",
    "# all variable and function:fixed\n",
    "lr = 0.2  # learning ratio\n",
    "epoch = 40\n",
    "for i in range(epoch):  # for epoch 定义顶层循环，表示对数据集循环epoch次，此例数据集数据仅有1个w,初始化时候constant赋值为5，循环40次迭代。\n",
    "    with tf.GradientTape() as g:  # with结构到grads框起了梯度的计算过程 same as get gradient\n",
    "        # g.watch(w) have been done\n",
    "        loss = tf.square(w + 1)\n",
    "    grads = g.gradient(loss, w)  # .gradient函数告知谁对谁求导\n",
    "\n",
    "    w.assign_sub(lr * grads)  # .assign_sub 对变量做自减 即：w -= lr*grads 即 w = w - lr*grads\n",
    "    print(\"After %s epoch,w is %f,loss is %f\" % (i, w.numpy(), loss))\n",
    "\n",
    "# lr初始值：0.2   请自改学习率  0.001  0.999 看收敛过程\n",
    "# 最终目的：找到 loss 最小 即 w = -1 的最优参数w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creat tensor(array, list)\n",
    "# convert to np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tf.Tensor([1 5], shape=(2,), dtype=int64)\n",
      "a.type: <dtype: 'int64'>\n",
      "a.shape: (2,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.constant([1, 5], dtype=tf.int64)  # create tensor with different dimension\n",
    "# same as list or array\n",
    "print(\"a:\", a)\n",
    "print(\"a.type:\", a.dtype)\n",
    "print(\"a.shape:\", a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: [0 1 2 3 4]\n",
      "b: tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# np to tensor!\n",
    "a = np.arange(0, 5)\n",
    "b = tf.convert_to_tensor(a, dtype=tf.int64)\n",
    "print(\"a:\", a)\n",
    "print(\"b:\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tf.Tensor(\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]], shape=(2, 3), dtype=float32)\n",
      "b: tf.Tensor([1. 1. 1. 1.], shape=(4,), dtype=float32)\n",
      "c: tf.Tensor(\n",
      "[[9. 9.]\n",
      " [9. 9.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# fill with number\n",
    "import tensorflow as tf\n",
    "a = tf.zeros([2, 3])  # 2*3 dimension\n",
    "b = tf.ones(4)\n",
    "c = tf.fill([2, 2], 9.0)  # fill with 9 c= tf.fill([a*b],n)!!!\n",
    "print(\"a:\", a)\n",
    "print(\"b:\", b)\n",
    "print(\"c:\", c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.random to create tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d: tf.Tensor(\n",
      "[[ 0.31969333 -0.45028627]\n",
      " [ 0.4603595  -0.2425406 ]], shape=(2, 2), dtype=float32)\n",
      "e: tf.Tensor(\n",
      "[[0.72652864 1.3106554 ]\n",
      " [1.2466094  1.2749703 ]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#normalize\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(5)\n",
    "d = tf.random.normal([2, 2], mean=0.5, stddev=1)\n",
    "print(\"d:\", d)\n",
    "# ensure inside some value\n",
    "# more concentrated\n",
    "e = tf.random.truncated_normal([2, 2], mean=0.5, stddev=1)  # ensure inside 2*stddev\n",
    "print(\"e:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f: tf.Tensor(\n",
      "[[0.94616044 0.2691307 ]\n",
      " [0.11571205 0.44424224]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# uniform, all same possibility\n",
    "import tensorflow as tf\n",
    "f = tf.random.uniform([2, 2], minval=0, maxval=1)\n",
    "print(\"f:\", f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function\n",
    "# axis =0 : col, axi=1: row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1: tf.Tensor([1. 2. 3.], shape=(3,), dtype=float64)\n",
      "x2 tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
      "minimum of x2： tf.Tensor(1, shape=(), dtype=int32)\n",
      "maxmum of x2: tf.Tensor(3, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# cast max min\n",
    "import tensorflow as tf\n",
    "x1 = tf.constant([1., 2., 3.], dtype=tf.float64)\n",
    "print(\"x1:\", x1)\n",
    "x2 = tf.cast(x1, tf.int32) # float to int\n",
    "print(\"x2\", x2)\n",
    "# get max min\n",
    "print(\"minimum of x2:\", tf.reduce_min(x2))\n",
    "print(\"maxmum of x2:\", tf.reduce_max(x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tf.Tensor(\n",
      "[[1 2 3]\n",
      " [2 2 3]], shape=(2, 3), dtype=int32)\n",
      "mean of x: tf.Tensor(2, shape=(), dtype=int32)\n",
      "sum of x: tf.Tensor([6 7], shape=(2,), dtype=int32)\n",
      "sum of x: tf.Tensor([2 2 3], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# mean, sum, axis!!!\n",
    "import tensorflow as tf\n",
    "x = tf.constant([[1, 2, 3], [2, 2, 3]])\n",
    "print(\"x:\", x)\n",
    "print(\"mean of x:\", tf.reduce_mean(x))  # 求x中所有数的均值\n",
    "print(\"sum of x:\", tf.reduce_sum(x, axis=1))  # 求每一行的和\n",
    "print(\"sum of x:\", tf.reduce_max(x, axis=0))  # 求每一行的和\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.Variable: means this is to be trained, mark it\n",
    "update when back-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
      "array([[ 1.2624669 ,  0.4385018 , -0.17315422],\n",
      "       [ 0.26691633,  0.3505242 ,  0.4593275 ]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "w = tf.Variable(tf.random.normal([2,3],mean =0,dtype=1))  # set w=5 as initial\n",
    "\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.0>\n",
      "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=-1.0>\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(tf.constant(1.0))  # set w=5 as init\n",
    "print(w)\n",
    "print(w.assign_sub(2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tf.Tensor([[1. 1. 1.]], shape=(1, 3), dtype=float32)\n",
      "b: tf.Tensor([[3. 3. 3.]], shape=(1, 3), dtype=float32)\n",
      "a+b: tf.Tensor([[4. 4. 4.]], shape=(1, 3), dtype=float32)\n",
      "a-b: tf.Tensor([[-2. -2. -2.]], shape=(1, 3), dtype=float32)\n",
      "a*b: tf.Tensor([[3. 3. 3.]], shape=(1, 3), dtype=float32)\n",
      "b/a: tf.Tensor([[3. 3. 3.]], shape=(1, 3), dtype=float32)\n",
      "a: tf.Tensor([[3. 3.]], shape=(1, 2), dtype=float32)\n",
      "a的平方: tf.Tensor([[27. 27.]], shape=(1, 2), dtype=float32)\n",
      "a的平方: tf.Tensor([[9. 9.]], shape=(1, 2), dtype=float32)\n",
      "a的开方: tf.Tensor([[1.7320508 1.7320508]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.ones([1, 3])\n",
    "b = tf.fill([1, 3], 3.)\n",
    "print(\"a:\", a)\n",
    "print(\"b:\", b)\n",
    "print(\"a+b:\", tf.add(a, b))\n",
    "print(\"a-b:\", tf.subtract(a, b))\n",
    "print(\"a*b:\", tf.multiply(a, b))\n",
    "print(\"b/a:\", tf.divide(b, a))\n",
    "a = tf.fill([1, 2], 3.)\n",
    "print(\"a:\", a)\n",
    "print(\"a的平方:\", tf.pow(a, 3))\n",
    "print(\"a的平方:\", tf.square(a))\n",
    "print(\"a的开方:\", tf.sqrt(a))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multiplication of two Matrix !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tf.Tensor(\n",
      "[[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]], shape=(3, 2), dtype=float32)\n",
      "b: tf.Tensor(\n",
      "[[3. 3. 3.]\n",
      " [3. 3. 3.]], shape=(2, 3), dtype=float32)\n",
      "a*b: tf.Tensor(\n",
      "[[6. 6. 6.]\n",
      " [6. 6. 6.]\n",
      " [6. 6. 6.]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.ones([3, 2])\n",
    "b = tf.fill([2, 3], 3.)\n",
    "print(\"a:\", a)\n",
    "print(\"b:\", b)\n",
    "print(\"a*b:\", tf.matmul(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# match lable with data!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=int32, numpy=12>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n",
      "(<tf.Tensor: shape=(), dtype=int32, numpy=23>, <tf.Tensor: shape=(), dtype=int32, numpy=1>)\n",
      "(<tf.Tensor: shape=(), dtype=int32, numpy=10>, <tf.Tensor: shape=(), dtype=int32, numpy=1>)\n",
      "(<tf.Tensor: shape=(), dtype=int32, numpy=17>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "features = tf.constant([12, 23, 10, 17])\n",
    "labels = tf.constant([0, 1, 1, 0])\n",
    "dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "for element in dataset:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get gradient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.Variable(tf.constant(3.0))\n",
    "with tf.GradientTape() as tape:\n",
    "    y = tf.pow(x, 2)\n",
    "grad = tape.gradient(y, x)\n",
    "print(grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 one\n",
      "1 two\n",
      "2 three\n",
      "(0, 'one')\n",
      "(1, 'two')\n",
      "(2, 'three')\n"
     ]
    }
   ],
   "source": [
    "seq = ['one', 'two', 'three']\n",
    "for i,element in enumerate(seq):\n",
    "    print(i,element)\n",
    "for element in enumerate(seq):\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one-hot --> used as lable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of labels1: tf.Tensor(\n",
      "[[0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]], shape=(6, 4), dtype=float32)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "classes = 4\n",
    "labels = tf.constant([1, 0, 2,3,2,0])  # 输入的元素值最小为0，最大为2\n",
    "output = tf.one_hot(labels, depth=classes)\n",
    "print(\"result of labels1:\", output)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nn.softmax for one-hot, possibility\n",
    " delet negative, more than 1, make the total of possiblity:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1.shape: (1, 4)\n",
      "w1.shape: (4, 3)\n",
      "b1.shape: (3,)\n",
      "y.shape: (1, 3)\n",
      "y: tf.Tensor([[ 1.0099998   2.008      -0.65999985]], shape=(1, 3), dtype=float32)\n",
      "y_dim: tf.Tensor([ 1.0099998   2.008      -0.65999985], shape=(3,), dtype=float32)\n",
      "y_pro: tf.Tensor([0.2563381  0.69540703 0.04825491], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "x1 = tf.constant([[5.8, 4.0, 1.2, 0.2]])  # 5.8,4.0,1.2,0.2（0）\n",
    "w1 = tf.constant([[-0.8, -0.34, -1.4],\n",
    "                  [0.6, 1.3, 0.25],\n",
    "                  [0.5, 1.45, 0.9],\n",
    "                  [0.65, 0.7, -1.2]])\n",
    "b1 = tf.constant([2.52, -3.1, 5.62])\n",
    "y = tf.matmul(x1, w1) + b1\n",
    "\n",
    "print(\"x1.shape:\", x1.shape)\n",
    "print(\"w1.shape:\", w1.shape)\n",
    "print(\"b1.shape:\", b1.shape)\n",
    "print(\"y.shape:\", y.shape)\n",
    "print(\"y:\", y)\n",
    "#####以下代码可将输出结果y转化为概率值#####\n",
    "y_dim = tf.squeeze(y)  # 去掉y中纬度1（观察y_dim与 y 效果对比）\n",
    "y_pro = tf.nn.softmax(y_dim)  # 使y_dim符合概率分布，输出为概率值了\n",
    "print(\"y_dim:\", y_dim)\n",
    "print(\"y_pro:\", y_pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After softmax, y_pro is: tf.Tensor([0.25598174 0.69583046 0.04818781], shape=(3,), dtype=float32)\n",
      "The sum of y_pro: tf.Tensor(1.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "y = tf.constant([1.01, 2.01, -0.66])\n",
    "y_pro = tf.nn.softmax(y)\n",
    "print(\"After softmax, y_pro is:\", y_pro)  # y_pro 符合概率分布\n",
    "print(\"The sum of y_pro:\", tf.reduce_sum(y_pro))  # 通过softmax后，所有概率加起来和为1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# self-update\n",
    "for variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=3>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.Variable(4)\n",
    "x.assign_sub(1)\n",
    "print(\"x:\", x)  # 4-1=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get index of max,min "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:\n",
      " [[1 2 3]\n",
      " [2 3 4]\n",
      " [5 4 3]\n",
      " [8 7 2]]\n",
      "每一列的最大值的索引 tf.Tensor([3 3 1], shape=(3,), dtype=int64)\n",
      "每一行的最大值的索引 tf.Tensor([2 2 0 0], shape=(4,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "test = np.array([[1, 2, 3], [2, 3, 4], [5, 4, 3], [8, 7, 2]])\n",
    "print(\"test:\\n\", test)\n",
    "print(\"每一列的最大值的索引\", tf.argmax(test, axis=0))  # 返回每一列最大值的索引\n",
    "print(\"每一行的最大值的索引\", tf.argmax(test, axis=1))  # 返回每一行最大值的索引\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read data true example\n",
    "iris as example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data add index: \n",
      "      花萼长度  花萼宽度  花瓣长度  花瓣宽度\n",
      "0         5.1       3.5       1.4       0.2\n",
      "1         4.9       3.0       1.4       0.2\n",
      "2         4.7       3.2       1.3       0.2\n",
      "3         4.6       3.1       1.5       0.2\n",
      "4         5.0       3.6       1.4       0.2\n",
      "..        ...       ...       ...       ...\n",
      "145       6.7       3.0       5.2       2.3\n",
      "146       6.3       2.5       5.0       1.9\n",
      "147       6.5       3.0       5.2       2.0\n",
      "148       6.2       3.4       5.4       2.3\n",
      "149       5.9       3.0       5.1       1.8\n",
      "\n",
      "[150 rows x 4 columns]\n",
      "x_data add a column: \n",
      "      花萼长度  花萼宽度  花瓣长度  花瓣宽度  类别\n",
      "0         5.1       3.5       1.4       0.2     0\n",
      "1         4.9       3.0       1.4       0.2     0\n",
      "2         4.7       3.2       1.3       0.2     0\n",
      "3         4.6       3.1       1.5       0.2     0\n",
      "4         5.0       3.6       1.4       0.2     0\n",
      "..        ...       ...       ...       ...   ...\n",
      "145       6.7       3.0       5.2       2.3     2\n",
      "146       6.3       2.5       5.0       1.9     2\n",
      "147       6.5       3.0       5.2       2.0     2\n",
      "148       6.2       3.4       5.4       2.3     2\n",
      "149       5.9       3.0       5.1       1.8     2\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "x_data = datasets.load_iris().data  # .data返回iris数据集所有输入特征\n",
    "y_data = datasets.load_iris().target  # .target返回iris数据集所有标签\n",
    "# give index and name\n",
    "# transfer list into table\n",
    "x_data = DataFrame(x_data, columns=['花萼长度', '花萼宽度', '花瓣长度', '花瓣宽度']) # 为表格增加行索引（左侧）和列标签（上方）\n",
    "pd.set_option('display.unicode.east_asian_width', True)  # 设置列名对齐\n",
    "print(\"x_data add index: \\n\", x_data)\n",
    "# add one into table with new name\n",
    "x_data['类别'] = y_data  # 新加一列，列标签为‘类别’，数据为y_data\n",
    "print(\"x_data add a column: \\n\", x_data)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "78431bbffb395ae8df1eebd6ffd005e9beb8cf9ce4bfad9a94a8db8fdf3c3aa2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
